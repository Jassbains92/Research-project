{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Analysis_ready.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>STATE</th>\n",
       "      <th>AGE_YRS</th>\n",
       "      <th>SEX</th>\n",
       "      <th>DIED</th>\n",
       "      <th>L_THREAT</th>\n",
       "      <th>ER_VISIT</th>\n",
       "      <th>HOSPITAL</th>\n",
       "      <th>HOSPDAYS</th>\n",
       "      <th>X_STAY</th>\n",
       "      <th>DISABLE</th>\n",
       "      <th>RECOVD</th>\n",
       "      <th>NUMDAYS</th>\n",
       "      <th>V_ADMINBY</th>\n",
       "      <th>V_FUNDBY</th>\n",
       "      <th>BIRTH_DEFECT</th>\n",
       "      <th>OFC_VISIT</th>\n",
       "      <th>ER_ED_VISIT</th>\n",
       "      <th>VAX_MANU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TX</td>\n",
       "      <td>33.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>PVT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MODERNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>73.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SEN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MODERNA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 STATE  AGE_YRS SEX  DIED  L_THREAT  ER_VISIT  HOSPITAL  \\\n",
       "0           0    TX     33.0   F     0         0         0         0   \n",
       "1           1    CA     73.0   F     0         0         0         0   \n",
       "\n",
       "   HOSPDAYS  X_STAY  DISABLE  RECOVD  NUMDAYS V_ADMINBY V_FUNDBY  \\\n",
       "0       0.0       0        0       1      2.0       PVT        0   \n",
       "1       0.0       0        0       1      0.0       SEN        0   \n",
       "\n",
       "   BIRTH_DEFECT  OFC_VISIT  ER_ED_VISIT VAX_MANU  \n",
       "0             0          1            0  MODERNA  \n",
       "1             0          1            0  MODERNA  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace([np.inf, -np.inf], 0)\n",
    "data = data.drop(['Unnamed: 0'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343491, 18)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing unwanted Column\n",
    "\n",
    "data = data.drop(['V_ADMINBY'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    339622\n",
       "1      3869\n",
       "Name: DIED, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mortality rate\n",
    "\n",
    "data['DIED'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE            True\n",
      "AGE_YRS         False\n",
      "SEX              True\n",
      "DIED            False\n",
      "L_THREAT        False\n",
      "ER_VISIT        False\n",
      "HOSPITAL        False\n",
      "HOSPDAYS        False\n",
      "X_STAY          False\n",
      "DISABLE         False\n",
      "RECOVD          False\n",
      "NUMDAYS         False\n",
      "V_FUNDBY         True\n",
      "BIRTH_DEFECT    False\n",
      "OFC_VISIT       False\n",
      "ER_ED_VISIT     False\n",
      "VAX_MANU         True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "obj = data.dtypes == np.object\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE\n",
      "SEX\n",
      "V_FUNDBY\n",
      "VAX_MANU\n"
     ]
    }
   ],
   "source": [
    "dummydf = pd.DataFrame()   \n",
    "for i in data.columns[obj]:\n",
    "    print(i)\n",
    "    dummy = pd.get_dummies(data[i], drop_first=True)\n",
    "    dummydf = pd.concat([dummydf, dummy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the dummy and dataset\n",
    "\n",
    "data_1 = data\n",
    "data_1 = pd.concat([data_1,dummydf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AK</th>\n",
       "      <th>AL</th>\n",
       "      <th>AR</th>\n",
       "      <th>AS</th>\n",
       "      <th>AZ</th>\n",
       "      <th>CA</th>\n",
       "      <th>CO</th>\n",
       "      <th>CT</th>\n",
       "      <th>Ca</th>\n",
       "      <th>DC</th>\n",
       "      <th>...</th>\n",
       "      <th>XV</th>\n",
       "      <th>M</th>\n",
       "      <th>U</th>\n",
       "      <th>0</th>\n",
       "      <th>OTH</th>\n",
       "      <th>PUB</th>\n",
       "      <th>PVT</th>\n",
       "      <th>UNK</th>\n",
       "      <th>MODERNA</th>\n",
       "      <th>PFIZER\\BIONTECH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AK  AL  AR  AS  AZ  CA  CO  CT  Ca  DC  ...  XV  M  U  0  OTH  PUB  PVT  \\\n",
       "0   0   0   0   0   0   0   0   0   0   0  ...   0  0  0  1    0    0    0   \n",
       "1   0   0   0   0   0   1   0   0   0   0  ...   0  0  0  1    0    0    0   \n",
       "2   0   0   0   0   0   0   0   0   0   0  ...   0  0  0  1    0    0    0   \n",
       "3   0   0   0   0   0   0   0   0   0   0  ...   0  0  0  1    0    0    0   \n",
       "4   0   0   0   0   0   0   0   0   0   0  ...   0  0  0  1    0    0    0   \n",
       "5   0   0   0   0   0   0   0   0   0   0  ...   0  0  0  1    0    0    0   \n",
       "6   0   0   0   0   0   0   0   0   0   0  ...   0  1  0  1    0    0    0   \n",
       "7   0   0   0   0   0   0   0   0   0   0  ...   0  1  0  1    0    0    0   \n",
       "8   0   0   0   0   0   0   0   0   0   0  ...   0  0  0  1    0    0    0   \n",
       "9   0   0   0   0   0   0   0   0   0   0  ...   0  0  0  1    0    0    0   \n",
       "\n",
       "   UNK  MODERNA  PFIZER\\BIONTECH  \n",
       "0    0        1                0  \n",
       "1    0        1                0  \n",
       "2    0        0                1  \n",
       "3    0        1                0  \n",
       "4    0        1                0  \n",
       "5    0        1                0  \n",
       "6    0        1                0  \n",
       "7    0        1                0  \n",
       "8    0        1                0  \n",
       "9    0        1                0  \n",
       "\n",
       "[10 rows x 71 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummydf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj1 = data_1.dtypes == np.object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATE               True\n",
       "AGE_YRS            False\n",
       "SEX                 True\n",
       "DIED               False\n",
       "L_THREAT           False\n",
       "                   ...  \n",
       "PUB                False\n",
       "PVT                False\n",
       "UNK                False\n",
       "MODERNA            False\n",
       "PFIZER\\BIONTECH    False\n",
       "Length: 88, dtype: bool"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = data_1.drop(data_1.columns[obj1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE_YRS</th>\n",
       "      <th>DIED</th>\n",
       "      <th>L_THREAT</th>\n",
       "      <th>ER_VISIT</th>\n",
       "      <th>HOSPITAL</th>\n",
       "      <th>HOSPDAYS</th>\n",
       "      <th>X_STAY</th>\n",
       "      <th>DISABLE</th>\n",
       "      <th>RECOVD</th>\n",
       "      <th>NUMDAYS</th>\n",
       "      <th>...</th>\n",
       "      <th>XV</th>\n",
       "      <th>M</th>\n",
       "      <th>U</th>\n",
       "      <th>0</th>\n",
       "      <th>OTH</th>\n",
       "      <th>PUB</th>\n",
       "      <th>PVT</th>\n",
       "      <th>UNK</th>\n",
       "      <th>MODERNA</th>\n",
       "      <th>PFIZER\\BIONTECH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE_YRS  DIED  L_THREAT  ER_VISIT  HOSPITAL  HOSPDAYS  X_STAY  DISABLE  \\\n",
       "0     33.0     0         0         0         0       0.0       0        0   \n",
       "1     73.0     0         0         0         0       0.0       0        0   \n",
       "2     23.0     0         0         0         0       0.0       0        0   \n",
       "3     58.0     0         0         0         0       0.0       0        0   \n",
       "4     47.0     0         0         0         0       0.0       0        0   \n",
       "\n",
       "   RECOVD  NUMDAYS  ...  XV  M  U  0  OTH  PUB  PVT  UNK  MODERNA  \\\n",
       "0       1      2.0  ...   0  0  0  1    0    0    0    0        1   \n",
       "1       1      0.0  ...   0  0  0  1    0    0    0    0        1   \n",
       "2       2      0.0  ...   0  0  0  1    0    0    0    0        0   \n",
       "3       1      0.0  ...   0  0  0  1    0    0    0    0        1   \n",
       "4       0      7.0  ...   0  0  0  1    0    0    0    0        1   \n",
       "\n",
       "   PFIZER\\BIONTECH  \n",
       "0                0  \n",
       "1                0  \n",
       "2                1  \n",
       "3                0  \n",
       "4                0  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGE_YRS            float64\n",
       "DIED                 int64\n",
       "L_THREAT             int64\n",
       "ER_VISIT             int64\n",
       "HOSPITAL             int64\n",
       "                    ...   \n",
       "PUB                  uint8\n",
       "PVT                  uint8\n",
       "UNK                  uint8\n",
       "MODERNA              uint8\n",
       "PFIZER\\BIONTECH      uint8\n",
       "Length: 84, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_1.drop(['DIED'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data_1['DIED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240443, 83)\n",
      "(240443,)\n",
      "(103048, 83)\n",
      "(103048,)\n"
     ]
    }
   ],
   "source": [
    "## Train Test Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30, random_state=7)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight of Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 1's : 3869\n"
     ]
    }
   ],
   "source": [
    "data_test = data_1.copy()\n",
    "\n",
    "data_test = data_test.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "print(\"Number of 1's :\", data_test.DIED.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information value of AGE_YRS is 1.432297\n",
      "Information value of L_THREAT is 0.01255\n",
      "Information value of ER_VISIT is inf\n",
      "Information value of HOSPITAL is 0.208083\n",
      "Information value of HOSPDAYS is 0.0\n",
      "Information value of X_STAY is 0.001383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information value of DISABLE is 0.001957\n",
      "Information value of RECOVD is 3.143333\n",
      "Information value of NUMDAYS is 0.55676\n",
      "Information value of BIRTH_DEFECT is 0.000212\n",
      "Information value of OFC_VISIT is 0.07528\n",
      "Information value of ER_ED_VISIT is 0.048825\n",
      "Information value of AK is 0.000962\n",
      "Information value of AL is 0.000266\n",
      "Information value of AR is 0.003041\n",
      "Information value of AS is inf\n",
      "Information value of AZ is 0.003898\n",
      "Information value of CA is 0.017771\n",
      "Information value of CO is 0.002519\n",
      "Information value of CT is 0.000711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information value of Ca is inf\n",
      "Information value of DC is 0.000142\n",
      "Information value of DE is 0.000599\n",
      "Information value of FL is 0.001643\n",
      "Information value of FM is inf\n",
      "Information value of GA is 0.000707\n",
      "Information value of GU is 0.000549\n",
      "Information value of HI is 0.000155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information value of IA is 0.000669\n",
      "Information value of ID is 0.000373\n",
      "Information value of IL is 0.001533\n",
      "Information value of IN is 0.019931\n",
      "Information value of KS is 0.001579\n",
      "Information value of KY is 0.016553\n",
      "Information value of LA is 0.000141\n",
      "Information value of MA is 0.003959\n",
      "Information value of MD is 0.003421\n",
      "Information value of ME is 5e-06\n",
      "Information value of MH is inf\n",
      "Information value of MI is 0.003281\n",
      "Information value of MN is 0.02692\n",
      "Information value of MO is 0.001578\n",
      "Information value of MP is 0.007533\n",
      "Information value of MS is 0.001315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information value of MT is 0.000901\n",
      "Information value of NC is 0.002643\n",
      "Information value of ND is 0.000614\n",
      "Information value of NE is 0.000339\n",
      "Information value of NH is 0.000887\n",
      "Information value of NJ is 0.003828\n",
      "Information value of NM is 5.7e-05\n",
      "Information value of NV is 6e-06\n",
      "Information value of NY is 0.00878\n",
      "Information value of OH is 8.3e-05\n",
      "Information value of OK is 0.008857\n",
      "Information value of OR is 0.00083\n",
      "Information value of PA is 0.000362\n",
      "Information value of PR is 0.034567\n",
      "Information value of QM is inf\n",
      "Information value of RI is 2.7e-05\n",
      "Information value of SC is 0.002834\n",
      "Information value of SD is 0.000173\n",
      "Information value of TN is 0.001967\n",
      "Information value of TX is 0.008546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information value of UT is 0.002066\n",
      "Information value of VA is 0.001005\n",
      "Information value of VI is inf\n",
      "Information value of VT is 0.000486\n",
      "Information value of WA is 0.001693\n",
      "Information value of WI is 3e-06\n",
      "Information value of WV is 0.00112\n",
      "Information value of WY is 0.000137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information value of XB is inf\n",
      "Information value of XV is inf\n",
      "Information value of M is 0.261113\n",
      "Information value of U is 0.004151\n",
      "Information value of 0 is 0.016303\n",
      "Information value of OTH is 0.004842\n",
      "Information value of PUB is 9.4e-05\n",
      "Information value of PVT is inf\n",
      "Information value of UNK is 3.6e-05\n",
      "Information value of MODERNA is 0.002044\n",
      "Information value of PFIZER\\BIONTECH is 0.005237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def iv_woe(data, target, bins=10, show_woe=False):\n",
    "    \n",
    "    #Empty Dataframe\n",
    "    newDF = pd.DataFrame()\n",
    "    \n",
    "    #Extract Column Names\n",
    "    cols = data.columns\n",
    "    \n",
    "    #Run WOE and IV on all the independent variables\n",
    "    for ivars in cols[~cols.isin([target])]:\n",
    "        if (data[ivars].dtype.kind in 'bifc') and (len(np.unique(data[ivars]))>10):\n",
    "            binned_x = pd.qcut(data[ivars], bins,  duplicates='drop')\n",
    "            d0 = pd.DataFrame({'x': binned_x, 'y': data[target]})\n",
    "        else:\n",
    "            d0 = pd.DataFrame({'x': data[ivars], 'y': data[target]})\n",
    "        d = d0.groupby(\"x\", as_index=False).agg({\"y\": [\"count\", \"sum\"]})\n",
    "        d.columns = ['Cutoff', 'N', 'Events']\n",
    "        d['% of Events'] = d['Events'] / d['Events'].sum()\n",
    "        d['Non-Events'] = d['N'] - d['Events']\n",
    "        d['% of Non-Events'] = d['Non-Events'] / d['Non-Events'].sum()\n",
    "        d.loc[d['% of Non-Events'] == 0.0,'% of Non-Events'] = 1e-312\n",
    "        d['WoE'] = np.log(d['% of Events']/d['% of Non-Events'])\n",
    "        d['IV'] = d['WoE'] * (d['% of Events'] - d['% of Non-Events'])\n",
    "        print(\"Information value of \" + ivars + \" is \" + str(round(d['IV'].sum(),6)))\n",
    "        temp =pd.DataFrame({\"Variable\" : [ivars], \n",
    "                            \"IV\" : [d['IV'].sum()]}, columns = [\"Variable\", \"IV\"])\n",
    "        newDF=pd.concat([newDF,temp], axis=0)\n",
    "\n",
    "        #Show WOE Table\n",
    "        if show_woe == True:\n",
    "            print(d)\n",
    "    return newDF\n",
    "iv_table = iv_woe(data = data_test, target = 'DIED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(343491, 83)\n",
      "(343491,)\n"
     ]
    }
   ],
   "source": [
    "def WoE_transform(data, target, bins=10, show_woe=False):\n",
    "    \n",
    "    #Empty Dataframe\n",
    "    newDF = pd.DataFrame()\n",
    "    newDF = pd.concat([newDF,data], axis=1)\n",
    "    \n",
    "    #Extract Column Names\n",
    "    cols = data.columns\n",
    "    \n",
    "    #Run WOE on all the independent variables\n",
    "    for ivars in cols[~cols.isin([target])]:\n",
    "\n",
    "        if (data[ivars].dtype.kind in 'bifc') and (len(np.unique(data[ivars]))>10):\n",
    "            binned_x = pd.qcut(data[ivars], bins,  duplicates='drop')\n",
    "            d0 = pd.DataFrame({'x': binned_x, 'y': data[target]})\n",
    "            \n",
    "            d = d0.groupby(\"x\", as_index=False).agg({\"y\": [\"count\", \"sum\"]})\n",
    "            d.columns = ['Cutoff', 'N', 'Events']\n",
    "            d['% of Events'] = d['Events'] / d['Events'].sum()\n",
    "            d['Non-Events'] = d['N'] - d['Events']\n",
    "            d['% of Non-Events'] = d['Non-Events'] / d['Non-Events'].sum()\n",
    "            d.loc[d['% of Non-Events'] == 0.0,'% of Non-Events'] = 1e-312\n",
    "            d['WoE'] = np.log(d['% of Events']/d['% of Non-Events'])\n",
    "\n",
    "            for i in range(d.shape[0]):\n",
    "                interval = d.iloc[i]['Cutoff']\n",
    "                left = interval.left\n",
    "                right = interval.right\n",
    "                IV_value = d.iloc[i]['WoE']\n",
    "                newDF.loc[(data[ivars] > left) & (data[ivars] <= right),ivars] = IV_value\n",
    "        else:\n",
    "            d0 = pd.DataFrame({'x': data[ivars], 'y': data[target]})\n",
    "            d = d0.groupby(\"x\", as_index=False).agg({\"y\": [\"count\", \"sum\"]})\n",
    "            d.columns = ['Cutoff', 'N', 'Events']\n",
    "            d['% of Events'] = d['Events'] / d['Events'].sum()\n",
    "            d['Non-Events'] = d['N'] - d['Events']\n",
    "            d['% of Non-Events'] = d['Non-Events'] / d['Non-Events'].sum()\n",
    "            d.loc[d['% of Non-Events'] == 0.0,'% of Non-Events'] = 1e-312\n",
    "            d['WoE'] = np.log(d['% of Events']/d['% of Non-Events'])\n",
    "\n",
    "            for i in range(d.shape[0]):\n",
    "                interval = d.iloc[i]['Cutoff']\n",
    "                WoE_value = d.iloc[i]['WoE']\n",
    "                newDF.loc[data[ivars] == interval,ivars] = WoE_value\n",
    "    for ivars in cols:\n",
    "        newDF[ivars] = newDF[ivars].astype('float64')\n",
    "    return newDF\n",
    "WoE_table = WoE_transform(data = data_test, target = 'DIED')\n",
    "\n",
    "X = WoE_table.drop('DIED', axis=1)\n",
    "Y = WoE_table['DIED']\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240443, 83)\n",
      "(240443,)\n",
      "(103048, 83)\n",
      "(103048,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30, random_state=7)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "X_train = X_train.replace([np.inf, -np.inf], 0)\n",
    "X_test = X_test.replace([np.inf, -np.inf], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "c = [0.001,0.01,0.1,1.0,10.0,100.0]\n",
    "num_cv_splits = 5\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "z_scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "X_train_z = z_scaler.fit_transform(X_train)\n",
    "X_test_z = z_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.001 ; mean accuracy = 0.9885794120491646 ; auc = 0.9294894748840884\n",
      "C = 0.01 ; mean accuracy = 0.98864179663768 ; auc = 0.9381648517686243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.1 ; mean accuracy = 0.9885960474378145 ; auc = 0.9399832117006705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 1.0 ; mean accuracy = 0.9885918883960578 ; auc = 0.9398156177789458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/krishm/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 10.0 ; mean accuracy = 0.988587729354301 ; auc = 0.9395139314894984\n",
      "C = 100.0 ; mean accuracy = 0.988587729354301 ; auc = 0.9396269673837858\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "c = [0.001,0.01,0.1,1.0,10.0,100.0]\n",
    "num_cv_splits = 5\n",
    "kf = KFold(n_splits=num_cv_splits)\n",
    "for C in c:\n",
    "    auc = 0.0\n",
    "    acc = 0.0\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        X_train_cv, X_test_cv = X_train_z[train_index], X_train_z[test_index]\n",
    "        Y_train_cv, Y_test_cv = Y_train.iloc[train_index], Y_train.iloc[test_index]\n",
    "        clf = LogisticRegression(C=C, random_state=5)\n",
    "        clf.fit(X_train_cv,Y_train_cv)\n",
    "        acc += clf.score(X_test_cv,Y_test_cv)\n",
    "        pred = clf.predict_proba(X_test_cv)[:,1]\n",
    "        auc += roc_auc_score(y_true = Y_test_cv, y_score = pred)\n",
    "    print('C =',C,'; mean accuracy =',acc/num_cv_splits,'; auc =',auc/num_cv_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score,roc_curve,confusion_matrix\n",
    "depths = [3,4,5,6,7,8,9,10,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth = 3 ; mean accuracy = 0.9885128685053786 ; auc = 0.9050642135743112\n",
      "depth = 4 ; mean accuracy = 0.9886334790730846 ; auc = 0.9183425705942225\n",
      "depth = 5 ; mean accuracy = 0.9886210019478143 ; auc = 0.923881791497051\n",
      "depth = 6 ; mean accuracy = 0.988645955938896 ; auc = 0.9317356185738145\n",
      "depth = 7 ; mean accuracy = 0.988779043545386 ; auc = 0.9369435282657708\n",
      "depth = 8 ; mean accuracy = 0.9887707265861948 ; auc = 0.935628463932465\n",
      "depth = 9 ; mean accuracy = 0.9887041820910591 ; auc = 0.9329831629239578\n",
      "depth = 10 ; mean accuracy = 0.9885752534398394 ; auc = 0.9304231598833084\n",
      "depth = 11 ; mean accuracy = 0.9883880988094293 ; auc = 0.9256084696419095\n"
     ]
    }
   ],
   "source": [
    "num_cv_splits = 5\n",
    "kf = KFold(n_splits=num_cv_splits)\n",
    "for depth in depths:\n",
    "    auc = 0.0\n",
    "    acc = 0.0\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        X_train_cv, X_test_cv = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        Y_train_cv, Y_test_cv = Y_train.iloc[train_index], Y_train.iloc[test_index]\n",
    "        clf = DecisionTreeClassifier(max_depth=depth, random_state=5)\n",
    "        clf.fit(X_train_cv,Y_train_cv)\n",
    "        acc += clf.score(X_test_cv,Y_test_cv)\n",
    "        pred = clf.predict_proba(X_test_cv)[:,1]\n",
    "        auc += roc_auc_score(y_true = Y_test_cv, y_score = pred)\n",
    "    print('depth =', depth, '; mean accuracy =', acc/num_cv_splits, '; auc =', auc/num_cv_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "num_trees = [25,50,75,100,125,150,175,200,225,250]\n",
    "max_depth = [3,4,5,6]\n",
    "num_cv_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_trees = 25 ; depth= 3 ; mean accuracy = 0.9885128685053786 ; auc = 0.9074575337532842\n",
      "num_trees = 25 ; depth= 4 ; mean accuracy = 0.9885128685053786 ; auc = 0.9032016222906899\n",
      "num_trees = 25 ; depth= 5 ; mean accuracy = 0.9885128685053786 ; auc = 0.9118238536922763\n",
      "num_trees = 25 ; depth= 6 ; mean accuracy = 0.9885170275471353 ; auc = 0.9231355089769087\n",
      "num_trees = 50 ; depth= 3 ; mean accuracy = 0.9885128685053786 ; auc = 0.9047749103124147\n",
      "num_trees = 50 ; depth= 4 ; mean accuracy = 0.9885128685053786 ; auc = 0.9110459679431624\n",
      "num_trees = 50 ; depth= 5 ; mean accuracy = 0.9885128685053786 ; auc = 0.9152264908004414\n",
      "num_trees = 50 ; depth= 6 ; mean accuracy = 0.9885128685053786 ; auc = 0.9263023157233391\n",
      "num_trees = 75 ; depth= 3 ; mean accuracy = 0.9885128685053786 ; auc = 0.9011595671267582\n",
      "num_trees = 75 ; depth= 4 ; mean accuracy = 0.9885128685053786 ; auc = 0.9072791621935297\n",
      "num_trees = 75 ; depth= 5 ; mean accuracy = 0.9885128685053786 ; auc = 0.9157533798501513\n",
      "num_trees = 75 ; depth= 6 ; mean accuracy = 0.9885128685053786 ; auc = 0.9254808195963908\n",
      "num_trees = 100 ; depth= 3 ; mean accuracy = 0.9885128685053786 ; auc = 0.9038031053248929\n",
      "num_trees = 100 ; depth= 4 ; mean accuracy = 0.9885128685053786 ; auc = 0.9080264796485679\n",
      "num_trees = 100 ; depth= 5 ; mean accuracy = 0.9885128685053786 ; auc = 0.9155943839758578\n",
      "num_trees = 100 ; depth= 6 ; mean accuracy = 0.9885128685053786 ; auc = 0.924220528497357\n",
      "num_trees = 125 ; depth= 3 ; mean accuracy = 0.9885128685053786 ; auc = 0.9041121038522976\n",
      "num_trees = 125 ; depth= 4 ; mean accuracy = 0.9885128685053786 ; auc = 0.9106867674916937\n",
      "num_trees = 125 ; depth= 5 ; mean accuracy = 0.9885128685053786 ; auc = 0.9170363527070828\n",
      "num_trees = 125 ; depth= 6 ; mean accuracy = 0.9885128685053786 ; auc = 0.925259490313598\n",
      "num_trees = 150 ; depth= 3 ; mean accuracy = 0.9885128685053786 ; auc = 0.902923486846705\n",
      "num_trees = 150 ; depth= 4 ; mean accuracy = 0.9885128685053786 ; auc = 0.9093960052239185\n",
      "num_trees = 150 ; depth= 5 ; mean accuracy = 0.9885128685053786 ; auc = 0.9157857736552699\n",
      "num_trees = 150 ; depth= 6 ; mean accuracy = 0.9885128685053786 ; auc = 0.9253481087614862\n",
      "num_trees = 175 ; depth= 3 ; mean accuracy = 0.9885128685053786 ; auc = 0.9030126645829502\n",
      "num_trees = 175 ; depth= 4 ; mean accuracy = 0.9885128685053786 ; auc = 0.9096674433781329\n",
      "num_trees = 175 ; depth= 5 ; mean accuracy = 0.9885128685053786 ; auc = 0.9154119231071032\n",
      "num_trees = 175 ; depth= 6 ; mean accuracy = 0.9885128685053786 ; auc = 0.9251679469695139\n",
      "num_trees = 200 ; depth= 3 ; mean accuracy = 0.9885128685053786 ; auc = 0.9030974495306726\n",
      "num_trees = 200 ; depth= 4 ; mean accuracy = 0.9885128685053786 ; auc = 0.9105835329762897\n",
      "num_trees = 200 ; depth= 5 ; mean accuracy = 0.9885128685053786 ; auc = 0.9168540714077394\n",
      "num_trees = 200 ; depth= 6 ; mean accuracy = 0.9885128685053786 ; auc = 0.9256970406721893\n",
      "num_trees = 225 ; depth= 3 ; mean accuracy = 0.9885128685053786 ; auc = 0.9024566742008643\n",
      "num_trees = 225 ; depth= 4 ; mean accuracy = 0.9885128685053786 ; auc = 0.9106360322911591\n",
      "num_trees = 225 ; depth= 5 ; mean accuracy = 0.9885128685053786 ; auc = 0.9168776781516996\n",
      "num_trees = 225 ; depth= 6 ; mean accuracy = 0.9885128685053786 ; auc = 0.9252407763917558\n",
      "num_trees = 250 ; depth= 3 ; mean accuracy = 0.9885128685053786 ; auc = 0.9022638026891402\n",
      "num_trees = 250 ; depth= 4 ; mean accuracy = 0.9885128685053786 ; auc = 0.9113454733409784\n",
      "num_trees = 250 ; depth= 5 ; mean accuracy = 0.9885128685053786 ; auc = 0.9170755174742556\n",
      "num_trees = 250 ; depth= 6 ; mean accuracy = 0.9885128685053786 ; auc = 0.9254693669416131\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=num_cv_splits)\n",
    "for tree in num_trees:\n",
    "    for depth in max_depth:\n",
    "        auc = 0.0\n",
    "        acc = 0.0\n",
    "        for train_index, test_index in kf.split(X_train):\n",
    "            X_train_cv, X_test_cv = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "            Y_train_cv, Y_test_cv = Y_train.iloc[train_index], Y_train.iloc[test_index]\n",
    "            clf = RandomForestClassifier(n_estimators=tree, max_depth=depth, n_jobs = 8, random_state=5)\n",
    "            clf.fit(X_train_cv,Y_train_cv)\n",
    "            acc += clf.score(X_test_cv,Y_test_cv)\n",
    "            pred = clf.predict_proba(X_test_cv)[:,1]\n",
    "            auc += roc_auc_score(y_true = Y_test_cv, y_score = pred)\n",
    "        print('num_trees =',tree,'; depth=',depth,'; mean accuracy =',acc/num_cv_splits,'; auc =',auc/num_cv_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_trees = 250 ; depth= 5 ; auc = 0.9176759539967\n"
     ]
    }
   ],
   "source": [
    "# Final model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "num_trees = 250\n",
    "max_depth = 5\n",
    "clf = RandomForestClassifier(n_estimators=num_trees, max_depth=max_depth, n_jobs = 4, random_state=5)\n",
    "clf.fit(X_train,Y_train)\n",
    "pred = clf.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_true = Y_test, y_score = pred[:,1])\n",
    "print('num_trees =',num_trees,'; depth=',max_depth,'; auc =',auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling with LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treatment of Class Imbalance - SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.1\n"
     ]
    }
   ],
   "source": [
    "# check version number\n",
    "import imblearn\n",
    "from collections import Counter\n",
    "print(imblearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 237681, 1.0: 2762})\n"
     ]
    }
   ],
   "source": [
    "# summarize class distribution\n",
    "counter = Counter(Y_train)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the dataset\n",
    "oversample = SMOTE()\n",
    "X_train, Y_train = oversample.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 237681, 1.0: 237681})\n"
     ]
    }
   ],
   "source": [
    "# summarize class distribution\n",
    "counter = Counter(Y_train)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(83,)),\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "475362/475362 [==============================] - 637s 1ms/step - loss: 0.2240 - accuracy: 0.9120\n",
      "Epoch 2/50\n",
      "475362/475362 [==============================] - 960s 2ms/step - loss: 0.1895 - accuracy: 0.9277\n",
      "Epoch 3/50\n",
      "475362/475362 [==============================] - 615s 1ms/step - loss: 0.1754 - accuracy: 0.9331\n",
      "Epoch 4/50\n",
      "475362/475362 [==============================] - 630s 1ms/step - loss: 0.1654 - accuracy: 0.9371\n",
      "Epoch 5/50\n",
      "475362/475362 [==============================] - 630s 1ms/step - loss: 0.1607 - accuracy: 0.9389\n",
      "Epoch 6/50\n",
      "475362/475362 [==============================] - 640s 1ms/step - loss: 0.1579 - accuracy: 0.9397\n",
      "Epoch 7/50\n",
      "475362/475362 [==============================] - 625s 1ms/step - loss: 0.1556 - accuracy: 0.94110s - l\n",
      "Epoch 8/50\n",
      "475362/475362 [==============================] - 632s 1ms/step - loss: 0.1540 - accuracy: 0.9415\n",
      "Epoch 9/50\n",
      "475362/475362 [==============================] - 990s 2ms/step - loss: 0.1530 - accuracy: 0.9420\n",
      "Epoch 10/50\n",
      "475362/475362 [==============================] - 636s 1ms/step - loss: 0.1520 - accuracy: 0.9423\n",
      "Epoch 11/50\n",
      "475362/475362 [==============================] - 728s 2ms/step - loss: 0.1512 - accuracy: 0.9422\n",
      "Epoch 12/50\n",
      "475362/475362 [==============================] - 610s 1ms/step - loss: 0.1504 - accuracy: 0.9423\n",
      "Epoch 13/50\n",
      "475362/475362 [==============================] - 625s 1ms/step - loss: 0.1496 - accuracy: 0.9428\n",
      "Epoch 14/50\n",
      "475362/475362 [==============================] - 2014s 4ms/step - loss: 0.1489 - accuracy: 0.9433\n",
      "Epoch 15/50\n",
      "475362/475362 [==============================] - 548s 1ms/step - loss: 0.1482 - accuracy: 0.9434\n",
      "Epoch 16/50\n",
      "475362/475362 [==============================] - 542s 1ms/step - loss: 0.1474 - accuracy: 0.9437\n",
      "Epoch 17/50\n",
      "475362/475362 [==============================] - 547s 1ms/step - loss: 0.1468 - accuracy: 0.9439\n",
      "Epoch 18/50\n",
      "475362/475362 [==============================] - 957s 2ms/step - loss: 0.1464 - accuracy: 0.9443\n",
      "Epoch 19/50\n",
      "475362/475362 [==============================] - 1116s 2ms/step - loss: 0.1455 - accuracy: 0.9446\n",
      "Epoch 20/50\n",
      "475362/475362 [==============================] - 617s 1ms/step - loss: 0.1445 - accuracy: 0.9446\n",
      "Epoch 21/50\n",
      "475362/475362 [==============================] - 667s 1ms/step - loss: 0.1439 - accuracy: 0.9449\n",
      "Epoch 22/50\n",
      "  7026/475362 [..............................] - ETA: 12:00 - loss: 0.1361 - accuracy: 0.9502"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-ad904c9e7750>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=50, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
